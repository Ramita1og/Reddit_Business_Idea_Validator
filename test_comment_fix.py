"""
æµ‹è¯•è¯„è®ºæ•°æ®åˆå¹¶ä¿®å¤
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from agents.orchestrator import OrchestratorAgent
from agents.config import ConfigManager
from agents.context_store import ContextStore
from agents.logging_config import setup_logging
from mcp_servers.reddit_server import RedditMCPServer
from mcp_servers.llm_server import create_llm_mcp_server
from mcp_servers.storage_server import create_storage_mcp_server


async def test_comment_merging():
    """æµ‹è¯•è¯„è®ºæ•°æ®åˆå¹¶"""
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    config = ConfigManager()
    log_level = config.get('logging.level', 'INFO')
    log_format = config.get('logging.format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    setup_logging(log_level=log_level, log_format=log_format)

    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    context_store = ContextStore()

    # è·å– API é…ç½®
    reddit_config = config.get_reddit_mcp_config()
    llm_config = config.get_llm_config()

    print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")

    # å¯åŠ¨ MCP æœåŠ¡å™¨
    reddit_server = RedditMCPServer(
        client_id=reddit_config.client_id,
        client_secret=reddit_config.client_secret,
        user_agent=reddit_config.user_agent
    )
    await reddit_server.start()
    llm_server = await create_llm_mcp_server(llm_config.api_key, llm_config.base_url)
    storage_server = await create_storage_mcp_server("agent_context/checkpoints")

    mcp_clients = {
        "reddit": reddit_server,
        "llm": llm_server,
        "storage": storage_server
    }

    print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ")

    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = OrchestratorAgent(config, context_store, mcp_clients)
    await orchestrator.start()

    # è®¾ç½®è¿›åº¦å›è°ƒ
    def progress_callback(update):
        bar_length = 30
        filled = int(bar_length * update.progress)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        print(f"  [{bar}] {update.progress*100:5.1f}% - {update.message}")

    orchestrator.set_progress_callback(progress_callback)

    # æ‰§è¡ŒéªŒè¯ - ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
    business_idea = "sell labubu to girls"
    print(f"\nğŸš€ å¼€å§‹éªŒè¯: {business_idea}\n")
    print("="*70)

    result = await orchestrator.execute(
        task="validate_business_idea",
        context={},
        business_idea=business_idea,
        keyword_count=1,
        pages_per_keyword=1,
        comments_per_post=5,
        report_format="html",
        use_user_input_as_keyword=True
    )

    # æ¸…ç†èµ„æº
    print("\nğŸ§¹ æ¸…ç†èµ„æº...")
    await orchestrator.stop()
    await reddit_server.stop()
    await llm_server.stop()
    await storage_server.stop()

    # è¾“å‡ºç»“æœ
    print("\n" + "="*70)
    if result.success:
        print("âœ… éªŒè¯å®Œæˆ!\n")

        data = result.data
        step_results = data.get("step_results", {})

        # æ˜¾ç¤ºæ•°æ®æŠ“å–ç»“æœ
        if "scrape_data" in step_results:
            sc_data = step_results["scrape_data"].get("data", {})
            metadata = sc_data.get("metadata", {})
            total_posts = metadata.get("total_posts", 0)
            posts_with_comments = metadata.get("posts_with_comments", 0)
            total_comments = metadata.get("total_comments", 0)

            print(f"ğŸ“Š æ•°æ®æŠ“å–:")
            print(f"   æ€»å¸–å­æ•°: {total_posts}")
            print(f"   å¸¦è¯„è®ºå¸–å­æ•°: {posts_with_comments}")
            print(f"   æ€»è¯„è®ºæ•°: {total_comments}")

            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå¸–å­çš„è¯„è®ºæ•°æ®
            posts = sc_data.get("posts_with_comments", [])
            if posts:
                first_post = posts[0]
                comments_data = first_post.get("comments_data", [])
                print(f"\nğŸ“ ç¬¬ä¸€ä¸ªå¸–å­è¯¦æƒ…:")
                print(f"   å¸–å­ID: {first_post.get('note_id')}")
                print(f"   æ ‡é¢˜: {first_post.get('title', '')[:50]}...")
                print(f"   è¯„è®ºæ•°: {len(comments_data)}")
                if comments_data:
                    print(f"   ç¬¬ä¸€æ¡è¯„è®º: {comments_data[0].get('content', '')[:50]}...")
                    print(f"   âœ… è¯„è®ºæ•°æ®åˆå¹¶æˆåŠŸ!")
                else:
                    print(f"   âŒ è¯„è®ºæ•°æ®ä¸ºç©º!")

        # æ˜¾ç¤ºè¯„è®ºæ ‡ç­¾åˆ†æç»“æœ
        if "analyze_comments_with_tags" in step_results:
            tag_data = step_results["analyze_comments_with_tags"].get("data", {})
            tag_analysis = tag_data.get("tag_analysis", {})
            total_posts_analyzed = tag_analysis.get("total_posts_analyzed", 0)
            total_tags_applied = tag_analysis.get("total_tags_applied", 0)

            print(f"\nğŸ·ï¸  è¯„è®ºæ ‡ç­¾åˆ†æ:")
            print(f"   åˆ†æå¸–å­æ•°: {total_posts_analyzed}")
            print(f"   åº”ç”¨æ ‡ç­¾æ•°: {total_tags_applied}")
            if total_posts_analyzed > 0:
                print(f"   âœ… è¯„è®ºæ ‡ç­¾åˆ†ææˆåŠŸ!")
            else:
                print(f"   âŒ è¯„è®ºæ ‡ç­¾åˆ†æå¤±è´¥!")

    else:
        print(f"âŒ éªŒè¯å¤±è´¥: {result.error}")

    print("="*70)

    return result.success


if __name__ == "__main__":
    try:
        success = asyncio.run(test_comment_merging())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
